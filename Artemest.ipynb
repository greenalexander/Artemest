{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-decline",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import all of the libraries I'll need\n",
    "# Note, Alex, I haven't included the time series-specific ones\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, classification_report\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats # for statistical calculations\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-visitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv('./CHANENAMEPLEASEALEX.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-headquarters",
   "metadata": {},
   "source": [
    "\n",
    "# GENERAL OVERVIEW AND EXPLORATION OF DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-validation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-novelty",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-identification",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data.tails(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-vector",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Columns are: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-cannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# change columns to something more uniform\n",
    "data.columns = ['ri','na','mg','al','si','k','ca','ba','fe','glass_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-conclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the time column to datetime and set as the index:\n",
    "#ALEX: note to make the format appropriate\n",
    "# Also, alex, you may not need to bother with the second of these things\n",
    "data.Month = pd.to_datetime(data.Month, format='%Y-%m')\n",
    "data.set_index('Month', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-gregory",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-creativity",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ALEX: this is probably where I change data types?\n",
    "\n",
    "# ALEX: also note that .info tells us about the number of entries /and/ non-null entries\n",
    "data.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-entrepreneur",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# change datatype\n",
    "data['COLUMN']=data.COLUMN.apply(lambda x: int(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-moral",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Methods for dealing with null:\n",
    "# Padding (repeating last non-null value) data.fillna(method='pad', inplace=True)\n",
    "# Filling 0's data.fillna(method=0, inplace=True)\n",
    "data.isnull().sum() # to show all nulls in each column\n",
    "data.COLUMN.fillna(value=data.COLUMN.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-bathroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Duplicate check\n",
    "users.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-filing",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dropping NAs - be careful!\n",
    "# drinks.dropna(how = 'all').reset_index(); can be used to drop either the entire row if there's any NAs, or if all NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-friendly",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data.describe(include = 'all') \n",
    "# ALEX: note I might need to set this as describe how = all, depending on the data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-strike",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-ebony",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Do the summaries from .info and .describe make any sense? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-buffer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-correspondence",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# new column with split apply\n",
    "data['NEWCoLUMN'] = data.OLDCOLUMN.apply(lambda x: 'large' if x >= a else 'low')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-cancellation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-civilian",
   "metadata": {},
   "source": [
    "\n",
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-turkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If useful, sort values by a certain variable\n",
    "data.sort_values('COLUMN NAME', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-eagle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-hurricane",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Summaries by columns\n",
    "data.groupby('OTHERCOLUMN').COLUMN.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-living",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get dummy variables\n",
    "data = data.join(pd.get_dummies(data['VARIABLE TO BE DUMMIED'], prefix='SOME PREFIX', prefix_sep='_'))\n",
    "# ALEX, note: drop_first=False is default; so maybe another line of code where I remove the base? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-ebony",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# histograms\n",
    "data.COLUMN.hist()\n",
    "\n",
    "# Below: histogram with normal curve. Note, 'sample' is the dataset\n",
    "def hist(sample):\n",
    "    # calculate the mean and standard deviation of the sample\n",
    "    mean = np.mean(sample)\n",
    "    sd = np.std(sample)\n",
    "\n",
    "    # create the histogram as before\n",
    "    n, bins, patches = plt.hist(sample, 20, density=1, facecolor='green', alpha=0.5)\n",
    "\n",
    "    # calculate a 'best fit' normal curve\n",
    "    y = stats.norm.pdf(bins, mean, sd)\n",
    "    \n",
    "    # plot the normal curve\n",
    "    l = plt.plot(bins, y, 'r--', linewidth=2, color='blue')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-mongolia",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# value-counts\n",
    "data.COLUMN.value_counts(dropna = False).plot(kind = 'bar') # can add sort_values or sort_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-finland",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot variables\n",
    "plt.scatter(data.INDEPENDENTV, data.DEPENDENTV)\n",
    "plt.xlabel('LABEL')\n",
    "plt.ylabel('LABEL')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-advancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# box plot\n",
    "data.boxplot(column='total_rentals', by='season');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-norway",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# correlation matrix for dataset\n",
    "data.corr()\n",
    "sns.heatmap(data.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-racing",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Unique\n",
    "data.COLUMN.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handy-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filtering\n",
    "data [data.COLUMN < 20];\n",
    "mask = data.COLUMN.str.contains('stud') #search for part of word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-diary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-luther",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop column \n",
    "data.drop('NAME', axis = 1)\n",
    "data.drop( data[(data.COLUMN == 4.9)].index.values[0]) # drop by a condition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-listening",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "functional-hamilton",
   "metadata": {},
   "source": [
    "# A/B Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-cabinet",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# all the correltion tests, e.g., pearsonr, spearmanr, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-eugene",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# I may need to do a shapiro wilks test for normality? \n",
    "p = stats.shapiro(samples.demo1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# anova (equal variance, normal dist)\n",
    "# non-normal anova (Kruskal wallis? I forgot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-constant",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# welch t-ttest (normal, but unequal var)\n",
    "p = stats.ttest_ind(pairs.demo1a, pairs.demo1b, equal_var=False).pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# mann-whitney u; at least 20 datapoints ine ach set\n",
    "p = stats.mannwhitneyu(pairs.demo2a, pairs.demo2b).pvalue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-pendant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "minus-census",
   "metadata": {},
   "source": [
    "\n",
    "# PICKING AND FITTING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-place",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ALEX\" general rule of thumb, check the assumptions that I'm making and if there are test for them\n",
    "    # e.g., shapiro wilks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-cliff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check for Multicolinearity!\n",
    "# Precise correlation varies, but typically 0.7/0.8. Look within industry. \n",
    "# Same with VIF. Often ~ 10, but some are more conservative and look at 5. \n",
    "correlations = data[['COLUMNS ', 'ANOTHER COLIUMN', 'casual']].corr()\n",
    "print(correlations)\n",
    "print(sns.heatmap(correlations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-diana",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Scatter plot a linear or logistic regression with trend line\n",
    "# https://seaborn.pydata.org/generated/seaborn.regplot.html; look here for robust for outliers\n",
    "# 'order' is the order of the plot, e.g., polynomial\n",
    "sns.regplot(x = 'al', y = 'ri', data = data, logistic = True, \n",
    "            robust = True, logx=False, x_partial=None, y_partial=None, truncate = True, order = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-apparel",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This might be where I include standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-generation",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fit a linear regression model (name the model \"linreg\").\n",
    "feature_cols = ['COLUMN NAMES']\n",
    "X=data[feature_cols]\n",
    "y=data['DEPENDENT VRAIBLE']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.7, random_state=1)\n",
    "\n",
    "    \n",
    "linreg = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-trail",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fit a logistic regression model and store the class predictions.\n",
    "feature_cols = ['COLUMN NAMES']\n",
    "X = data[feature_cols]\n",
    "y = data.DEPENDENT\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.7, random_state=1)\n",
    "\n",
    "logreg = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-friendship",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-theme",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make predictions for X_test values and add back to the original DataFrame.\n",
    "y_pred = linreg.predict(X_test)\n",
    "\n",
    "# new column of y_pred\n",
    "data['y_pred'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "returning-special",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-puppy",
   "metadata": {},
   "source": [
    "\n",
    "# EXAMINING, REFINING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-armenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ALEX: NOTE: for a linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-twist",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print('Score: ' + str(lr.score(X_test,y_test)))\n",
    "print('RMSE: ' + str(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuing-adrian",
   "metadata": {},
   "source": [
    "\n",
    "## for p-values and such\n",
    "\n",
    "https://stackoverflow.com/questions/27928275/find-p-value-significance-in-scikit-learn-linearregression\n",
    "\n",
    "X_train = sm.add_constant(X_train) --- do I need this line of code?\n",
    "linreg = sm.OLS(y_train, X_train)\n",
    "result = linreg.fit()\n",
    "print(result.summary())\n",
    "\n",
    "\n",
    "We want deviance residual to be close to 0; we could do a chi-sq test here to figure out the usefulness of the model\n",
    "\n",
    "The Akaike information criterion (AIC) is a metric that is used to compare the fit of different regression models. The lower the value, the better the regression model is able to fit the data. The actual value for the AIC is meaningless.\n",
    "\n",
    "Chi-sq: Resid deviance - null deviance, also with their dfs -> chi-sq and degrees of freedom\n",
    "\n",
    "https://www.statsmodels.org/dev/generated/statsmodels.stats.anova.anova_lm.html\n",
    "THiS IS FOR DOING ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-seventh",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ALEX\" NOTE: For a logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-conviction",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Confusion matrix; maybe worth moving up? Can be useful\n",
    "plot_confusion_matrix(MODELNAME,X_test,y_test)\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-multimedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# .score\n",
    "data['DEPENDENT'].value_counts(normalize=True).max()\n",
    "MODELNAME.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-diabetes",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# For the other kinds of metrics\n",
    "y_pred=logit_simple.predict(X_test)\n",
    "print('Recall: ' +str(recall_score(y_pred,y_test)))\n",
    "print('Precision: ' +str(precision_score(y_pred,y_test)))\n",
    "print(classification_report(y_test, y_pred))\n",
    "# Useful documentation\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html#sklearn.metrics.precision_recall_fscore_support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-middle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "legendary-lithuania",
   "metadata": {},
   "source": [
    "\n",
    "## for p-values and such\n",
    "\n",
    "logit_model=sm.Logit(y_train,X_train)\n",
    "result=logit_model.fit()\n",
    "print(result.summary())\n",
    "\n",
    "Compare the log-likelihood ratios of different models. Code for doing this is below: \n",
    "\n",
    "https://stackoverflow.com/questions/69162676/statsmodels-metric-for-comparing-logistic-regression-models\n",
    "from scipy.stats.distributions import chi2\n",
    "from statsmodels.discrete.discrete_model import BinaryResultsWrapper\n",
    "import statsmodels.api as sm \n",
    "\n",
    "\n",
    "def likelihood_ratio(ll0, ll1):\n",
    "    return -2 * (ll0-ll1)\n",
    "\n",
    "def lrtest(fitted_model0: BinaryResultsWrapper, \n",
    "           fitted_model1: BinaryResultsWrapper) -> (float, float):\n",
    "    \n",
    "    L0, L1 = fitted_model0.llf, fitted_model1.llf\n",
    "    df0, df1 = fitted_model0.df_model, fitted_model1.df_model\n",
    "    \n",
    "    chi2_stat = likelihood_ratio(L0,L1)\n",
    "    p = chi2.sf(chi2_stat, df1-df0)\n",
    "\n",
    "    return (chi2_stat, p)\n",
    "\n",
    "log_mod0 = sm.Logit(y_var, X_vars0).fit()\n",
    "log_mod1 = sm.Logit(y_var, X_vars1).fit()\n",
    "\n",
    "chi2_stat, p = lrtest(log_mod0, log_mod1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-plaintiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALEX: HOW CAN I GET A P_VALUE? WHAT DOES r GENERATE from a log reg? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-branch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-radar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-hammer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-confusion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fitting-endorsement",
   "metadata": {},
   "source": [
    "\n",
    "# INTERPRETING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-brook",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model coefficients\n",
    "print(linreg.intercept_)\n",
    "print(linreg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-thunder",
   "metadata": {},
   "source": [
    "\n",
    "FOR YOUR UNDERSTANDING: If the coefficient is positive, it means for every 1 unit increase of that feature, the chance/odds it assigns the default label is increasing while the opposite is true for negative coefficients.\n",
    "    \n",
    "MORE TECHNICALLY SPEAKING:   \n",
    "If X is continuous, we can say: 'The odds of being assigned to label 1 increase by e^(coefficient) for a 1-unit increase in X'; the odds of someone having a degree increase by e^coeff for each year of age. \n",
    "If X is binary, we can say: 'The odds of being assigned to label 1 are e^(coefficient) higher for group A as compared to group B'; the odds of someone having a degree are e^coef higher if their parents have degrees as compared to if their parents do not have a degree. \n",
    "    \n",
    "Note: odds != probability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-power",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-mixer",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# use mdoel to make predictions\n",
    "linreg.predict([[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-compression",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-dinner",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "imperial-display",
   "metadata": {},
   "source": [
    "\n",
    "# ALEX: EXTRA POSSIBLY NEEDED CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-internet",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Take the log of the data\n",
    "data['log'] = np.log(data['COLUMN NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-frost",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standard scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "bikes_predict=bikes.drop('total_rentals',axis=1) # Remove target variable before standardisation\n",
    "bikes_standard=scaler.fit_transform(bikes_predict)\n",
    "bikes_standard_df=pd.DataFrame(bikes_standard,columns=bikes_predict.columns,index=bikes.index)\n",
    "\n",
    "# When to do this? Vastly different scales, multicolinearity, and interaction terms\n",
    "# It's probably generally worth doing this, so consider it in the feature engineering section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "affecting-exhibition",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Dataset' object has no attribute 'info'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-eb9c5e7330ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspector_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'info'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Reularization goes here, but only if I think the model will be too complex already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-turner",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# k-fold and cross-validation!!! and three-way; I'll need to look at this again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-jewelry",
   "metadata": {},
   "source": [
    "\n",
    "1. Split our data into a number of different pieces (folds).\n",
    "2. Train using `k-1` folds for training and a different fold for testing.\n",
    "3. Average our model against EACH of those iterations.\n",
    "4. Choose our model and TEST it against the final fold.\n",
    "5. Average all test accuracies to get the estimated out-of-sample accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-soccer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/54307137/how-to-get-coefficients-with-cross-validation-model\n",
    "  # This is how to get the estimates and such  - evaluate the model with cross-val, and then fit \n",
    "        # the coefficients on the entire dataset (I think?)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
